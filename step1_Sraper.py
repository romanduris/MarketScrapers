"""
Step 1 ‚Äì Scraper v3
Z√≠skava dynamick√Ω zoznam akciov√Ωch kandid√°tov z Yahoo Finance (API).
V√Ωstup: data/step1_candidates.json
"""

import json
from pathlib import Path
from datetime import date
import requests
import yfinance as yf
from bs4 import BeautifulSoup

# ---------- KONFIGUR√ÅCIA ----------
OUTPUT_FILE = "data/step1_candidates.json"
MAX_PER_SOURCE = 50
HEADERS = {"User-Agent": "Mozilla/5.0"}

# ---------- YAHOO FINANCE ----------
def get_yahoo_stocks():
    """Z√≠ska top tickery z Yahoo Finance pomocou API"""
    urls = {
        "most_active": "https://finance.yahoo.com/most-active",
        "gainers": "https://finance.yahoo.com/gainers",
    }
    tickers = []

    print("üì° Naƒç√≠tavam d√°ta z Yahoo Finance...")
    for name, url in urls.items():
        try:
            resp = requests.get(url, headers=HEADERS, timeout=10)
            soup = BeautifulSoup(resp.text, "html.parser")
            rows = soup.select("table tbody tr")

            for row in rows[:MAX_PER_SOURCE]:
                cols = row.find_all("td")
                if len(cols) < 3:
                    continue

                ticker = cols[0].text.strip()
                company = cols[1].text.strip()

                try:
                    stock = yf.Ticker(ticker)
                    info = stock.info
                    percent_change = round(info.get("regularMarketChangePercent", 0.0), 2)
                    volume = info.get("volume", 0)
                    avg_volume = info.get("averageVolume", 1)  # aby nedo≈°lo k deleniu nulou
                    volume_gain = round((volume - avg_volume) / avg_volume * 100, 2)
                except Exception:
                    percent_change, volume, volume_gain = 0.0, 0, 0.0

                tickers.append({
                    "ticker": ticker,
                    "name": company,
                    "volume": volume,
                    "average_volume": avg_volume,
                    "volume_gain": volume_gain,
                    "percent_change": percent_change,
                    "source": f"Yahoo:{name}",
                    "date": str(date.today())
                })
        except Exception as e:
            print(f"‚ö†Ô∏è Chyba pri naƒç√≠tan√≠ Yahoo sekcie {name}: {e}")

    print(f"‚úÖ Yahoo Finance: z√≠skan√Ωch {len(tickers)} z√°znamov")
    return tickers

# ---------- HLAVN√Å FUNKCIA ----------
def run_scraper():
    print("üöÄ Sp√∫≈°≈•am Step 1 ‚Äì Scraper V3")

    yahoo_data = get_yahoo_stocks()
    deduped = {i["ticker"]: i for i in yahoo_data}  # dedup podƒæa tickeru
    deduped_list = list(deduped.values())

    Path("data").mkdir(exist_ok=True)
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(deduped_list, f, indent=2, ensure_ascii=False)

    print("\nüìä ≈†TATISTIKA SCRAPERU")
    print(f"- üü£ Yahoo Finance: {len(yahoo_data)} akci√≠")
    print(f"- üîµ Po deduplik√°cii: {len(deduped_list)} unik√°tnych akci√≠")
    print(f"- üíæ V√Ωstup ulo≈æen√Ω do: {OUTPUT_FILE}")
    
    return deduped_list

# ---------- SPUSTENIE ----------
if __name__ == "__main__":
    run_scraper()
